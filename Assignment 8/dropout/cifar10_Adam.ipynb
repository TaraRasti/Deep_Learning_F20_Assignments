{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-Adam.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOPX0hwOUJc5xxKXRngWiZ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaraRasti/Deep_Learning_F20_Assignments/blob/master/Assignment%208/dropout/cifar10_Adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HooCuGDj0S_v",
        "outputId": "6deb7b71-2698-48ee-e6b6-54b9a137c81e"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "#z-score\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "\n",
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)\n",
        "\n",
        "baseMapNum = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "#training\n",
        "batch_size = 64\n",
        "epochs=25\n",
        "opt_rms = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep75.h5')\n",
        "\n",
        "opt_rms = keras.optimizers.Adam(lr=0.0005,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep100.h5')\n",
        "\n",
        "opt_rms = keras.optimizers.Adam(lr=0.0003,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep125.h5')\n",
        "\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Epoch 1/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.7506 - accuracy: 0.4090 - val_loss: 2.2152 - val_accuracy: 0.5361\n",
            "Epoch 2/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.0557 - accuracy: 0.5536 - val_loss: 1.7181 - val_accuracy: 0.6410\n",
            "Epoch 3/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.7188 - accuracy: 0.6236 - val_loss: 1.5415 - val_accuracy: 0.6801\n",
            "Epoch 4/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5336 - accuracy: 0.6641 - val_loss: 1.4329 - val_accuracy: 0.6943\n",
            "Epoch 5/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4292 - accuracy: 0.6932 - val_loss: 1.3628 - val_accuracy: 0.7237\n",
            "Epoch 6/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 1.3667 - accuracy: 0.7102 - val_loss: 1.4337 - val_accuracy: 0.7150\n",
            "Epoch 7/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.3183 - accuracy: 0.7249 - val_loss: 1.1960 - val_accuracy: 0.7681\n",
            "Epoch 8/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.2890 - accuracy: 0.7355 - val_loss: 1.2586 - val_accuracy: 0.7529\n",
            "Epoch 9/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.2672 - accuracy: 0.7434 - val_loss: 1.2087 - val_accuracy: 0.7636\n",
            "Epoch 10/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.2345 - accuracy: 0.7502 - val_loss: 1.3213 - val_accuracy: 0.7321\n",
            "Epoch 11/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.2139 - accuracy: 0.7575 - val_loss: 1.2170 - val_accuracy: 0.7636\n",
            "Epoch 12/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 1.1991 - accuracy: 0.7586 - val_loss: 1.1289 - val_accuracy: 0.7894\n",
            "Epoch 13/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.1792 - accuracy: 0.7665 - val_loss: 1.1991 - val_accuracy: 0.7652\n",
            "Epoch 14/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.1590 - accuracy: 0.7698 - val_loss: 1.3453 - val_accuracy: 0.7431\n",
            "Epoch 15/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.1522 - accuracy: 0.7713 - val_loss: 1.1234 - val_accuracy: 0.7847\n",
            "Epoch 16/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 1.1332 - accuracy: 0.7762 - val_loss: 1.1012 - val_accuracy: 0.7891\n",
            "Epoch 17/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.1258 - accuracy: 0.7744 - val_loss: 1.0932 - val_accuracy: 0.7890\n",
            "Epoch 18/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 1.1108 - accuracy: 0.7801 - val_loss: 1.0596 - val_accuracy: 0.8014\n",
            "Epoch 19/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 1.1091 - accuracy: 0.7791 - val_loss: 1.1435 - val_accuracy: 0.7734\n",
            "Epoch 20/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0999 - accuracy: 0.7818 - val_loss: 1.0726 - val_accuracy: 0.7963\n",
            "Epoch 21/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0858 - accuracy: 0.7845 - val_loss: 1.0869 - val_accuracy: 0.7903\n",
            "Epoch 22/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0806 - accuracy: 0.7839 - val_loss: 1.0344 - val_accuracy: 0.8066\n",
            "Epoch 23/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0733 - accuracy: 0.7854 - val_loss: 1.0253 - val_accuracy: 0.8116\n",
            "Epoch 24/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0643 - accuracy: 0.7896 - val_loss: 1.0139 - val_accuracy: 0.8139\n",
            "Epoch 25/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0630 - accuracy: 0.7884 - val_loss: 1.1116 - val_accuracy: 0.7837\n",
            "Epoch 26/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0644 - accuracy: 0.7881 - val_loss: 1.0909 - val_accuracy: 0.7893\n",
            "Epoch 27/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0547 - accuracy: 0.7892 - val_loss: 1.0578 - val_accuracy: 0.8012\n",
            "Epoch 28/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0499 - accuracy: 0.7927 - val_loss: 1.0558 - val_accuracy: 0.7946\n",
            "Epoch 29/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 1.0441 - accuracy: 0.7932 - val_loss: 1.1088 - val_accuracy: 0.7810\n",
            "Epoch 30/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 1.0396 - accuracy: 0.7944 - val_loss: 1.0340 - val_accuracy: 0.8064\n",
            "Epoch 31/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 1.0423 - accuracy: 0.7929 - val_loss: 1.0232 - val_accuracy: 0.8054\n",
            "Epoch 32/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0394 - accuracy: 0.7945 - val_loss: 0.9877 - val_accuracy: 0.8137\n",
            "Epoch 33/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0310 - accuracy: 0.7968 - val_loss: 1.0677 - val_accuracy: 0.7859\n",
            "Epoch 34/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0287 - accuracy: 0.7974 - val_loss: 1.1515 - val_accuracy: 0.7683\n",
            "Epoch 35/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0324 - accuracy: 0.7967 - val_loss: 1.0954 - val_accuracy: 0.7874\n",
            "Epoch 36/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0273 - accuracy: 0.7987 - val_loss: 1.0372 - val_accuracy: 0.8020\n",
            "Epoch 37/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0160 - accuracy: 0.8010 - val_loss: 0.9545 - val_accuracy: 0.8238\n",
            "Epoch 38/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0203 - accuracy: 0.7990 - val_loss: 1.1166 - val_accuracy: 0.7778\n",
            "Epoch 39/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0144 - accuracy: 0.8005 - val_loss: 1.1157 - val_accuracy: 0.7820\n",
            "Epoch 40/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0135 - accuracy: 0.8012 - val_loss: 0.9709 - val_accuracy: 0.8204\n",
            "Epoch 41/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0119 - accuracy: 0.8020 - val_loss: 1.0801 - val_accuracy: 0.7874\n",
            "Epoch 42/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0036 - accuracy: 0.8048 - val_loss: 0.9773 - val_accuracy: 0.8226\n",
            "Epoch 43/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0131 - accuracy: 0.7999 - val_loss: 1.0492 - val_accuracy: 0.7937\n",
            "Epoch 44/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 1.0055 - accuracy: 0.8030 - val_loss: 1.0206 - val_accuracy: 0.8051\n",
            "Epoch 45/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0062 - accuracy: 0.8030 - val_loss: 0.9742 - val_accuracy: 0.8198\n",
            "Epoch 46/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0034 - accuracy: 0.8026 - val_loss: 1.1062 - val_accuracy: 0.7773\n",
            "Epoch 47/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0014 - accuracy: 0.8032 - val_loss: 1.0559 - val_accuracy: 0.7961\n",
            "Epoch 48/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0004 - accuracy: 0.8045 - val_loss: 1.0036 - val_accuracy: 0.8099\n",
            "Epoch 49/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9987 - accuracy: 0.8064 - val_loss: 0.9887 - val_accuracy: 0.8096\n",
            "Epoch 50/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9987 - accuracy: 0.8038 - val_loss: 1.0261 - val_accuracy: 0.8018\n",
            "Epoch 51/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9989 - accuracy: 0.8029 - val_loss: 0.9379 - val_accuracy: 0.8327\n",
            "Epoch 52/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9979 - accuracy: 0.8052 - val_loss: 0.9659 - val_accuracy: 0.8186\n",
            "Epoch 53/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9910 - accuracy: 0.8077 - val_loss: 0.9445 - val_accuracy: 0.8292\n",
            "Epoch 54/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9960 - accuracy: 0.8035 - val_loss: 0.9397 - val_accuracy: 0.8229\n",
            "Epoch 55/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9916 - accuracy: 0.8079 - val_loss: 0.9413 - val_accuracy: 0.8250\n",
            "Epoch 56/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9896 - accuracy: 0.8060 - val_loss: 1.0070 - val_accuracy: 0.8085\n",
            "Epoch 57/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9889 - accuracy: 0.8062 - val_loss: 0.9677 - val_accuracy: 0.8144\n",
            "Epoch 58/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9864 - accuracy: 0.8074 - val_loss: 1.0404 - val_accuracy: 0.7987\n",
            "Epoch 59/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9903 - accuracy: 0.8072 - val_loss: 0.9543 - val_accuracy: 0.8231\n",
            "Epoch 60/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9872 - accuracy: 0.8073 - val_loss: 1.0323 - val_accuracy: 0.8018\n",
            "Epoch 61/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9852 - accuracy: 0.8082 - val_loss: 1.0796 - val_accuracy: 0.7893\n",
            "Epoch 62/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9857 - accuracy: 0.8085 - val_loss: 0.9410 - val_accuracy: 0.8290\n",
            "Epoch 63/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.9868 - accuracy: 0.8088 - val_loss: 0.9699 - val_accuracy: 0.8141\n",
            "Epoch 64/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9813 - accuracy: 0.8085 - val_loss: 0.9617 - val_accuracy: 0.8246\n",
            "Epoch 65/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9764 - accuracy: 0.8104 - val_loss: 0.9320 - val_accuracy: 0.8308\n",
            "Epoch 66/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.9815 - accuracy: 0.8084 - val_loss: 0.9487 - val_accuracy: 0.8230\n",
            "Epoch 67/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9804 - accuracy: 0.8089 - val_loss: 0.9241 - val_accuracy: 0.8320\n",
            "Epoch 68/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.9751 - accuracy: 0.8089 - val_loss: 1.0444 - val_accuracy: 0.7998\n",
            "Epoch 69/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9745 - accuracy: 0.8100 - val_loss: 0.9509 - val_accuracy: 0.8236\n",
            "Epoch 70/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9758 - accuracy: 0.8104 - val_loss: 0.9160 - val_accuracy: 0.8362\n",
            "Epoch 71/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9767 - accuracy: 0.8086 - val_loss: 0.9188 - val_accuracy: 0.8348\n",
            "Epoch 72/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.9734 - accuracy: 0.8109 - val_loss: 0.9798 - val_accuracy: 0.8153\n",
            "Epoch 73/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9780 - accuracy: 0.8093 - val_loss: 0.9446 - val_accuracy: 0.8233\n",
            "Epoch 74/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9756 - accuracy: 0.8118 - val_loss: 0.9534 - val_accuracy: 0.8230\n",
            "Epoch 75/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9689 - accuracy: 0.8107 - val_loss: 0.9446 - val_accuracy: 0.8226\n",
            "Epoch 1/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.9010 - accuracy: 0.8263 - val_loss: 0.8486 - val_accuracy: 0.8428\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8665 - accuracy: 0.8309 - val_loss: 0.8460 - val_accuracy: 0.8399\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8541 - accuracy: 0.8321 - val_loss: 0.7878 - val_accuracy: 0.8542\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8461 - accuracy: 0.8330 - val_loss: 0.8330 - val_accuracy: 0.8384\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8405 - accuracy: 0.8327 - val_loss: 0.8755 - val_accuracy: 0.8248\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8344 - accuracy: 0.8311 - val_loss: 0.8652 - val_accuracy: 0.8277\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.8231 - accuracy: 0.8356 - val_loss: 0.9227 - val_accuracy: 0.8118\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8278 - accuracy: 0.8337 - val_loss: 0.8138 - val_accuracy: 0.8422\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8220 - accuracy: 0.8324 - val_loss: 0.8123 - val_accuracy: 0.8431\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8208 - accuracy: 0.8341 - val_loss: 0.7836 - val_accuracy: 0.8506\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8186 - accuracy: 0.8333 - val_loss: 0.8286 - val_accuracy: 0.8340\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8152 - accuracy: 0.8353 - val_loss: 0.7898 - val_accuracy: 0.8474\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8149 - accuracy: 0.8343 - val_loss: 0.7763 - val_accuracy: 0.8506\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8106 - accuracy: 0.8353 - val_loss: 0.8027 - val_accuracy: 0.8421\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8079 - accuracy: 0.8341 - val_loss: 0.8355 - val_accuracy: 0.8356\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8147 - accuracy: 0.8342 - val_loss: 0.8247 - val_accuracy: 0.8355\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8088 - accuracy: 0.8354 - val_loss: 0.8063 - val_accuracy: 0.8397\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8073 - accuracy: 0.8344 - val_loss: 0.8078 - val_accuracy: 0.8382\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8124 - accuracy: 0.8340 - val_loss: 0.7790 - val_accuracy: 0.8513\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.8002 - accuracy: 0.8388 - val_loss: 0.7895 - val_accuracy: 0.8444\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8042 - accuracy: 0.8344 - val_loss: 0.7545 - val_accuracy: 0.8552\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8017 - accuracy: 0.8371 - val_loss: 0.7870 - val_accuracy: 0.8453\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8016 - accuracy: 0.8381 - val_loss: 0.8341 - val_accuracy: 0.8325\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.8001 - accuracy: 0.8367 - val_loss: 0.7881 - val_accuracy: 0.8460\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.7964 - accuracy: 0.8379 - val_loss: 0.7847 - val_accuracy: 0.8442\n",
            "Epoch 1/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.7637 - accuracy: 0.8455 - val_loss: 0.7274 - val_accuracy: 0.8581\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.7448 - accuracy: 0.8504 - val_loss: 0.7166 - val_accuracy: 0.8602\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7423 - accuracy: 0.8474 - val_loss: 0.7341 - val_accuracy: 0.8553\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7331 - accuracy: 0.8479 - val_loss: 0.7247 - val_accuracy: 0.8548\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7297 - accuracy: 0.8489 - val_loss: 0.7473 - val_accuracy: 0.8496\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.7242 - accuracy: 0.8512 - val_loss: 0.7712 - val_accuracy: 0.8425\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7197 - accuracy: 0.8511 - val_loss: 0.7524 - val_accuracy: 0.8492\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.7244 - accuracy: 0.8485 - val_loss: 0.7400 - val_accuracy: 0.8498\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7173 - accuracy: 0.8500 - val_loss: 0.7102 - val_accuracy: 0.8575\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7141 - accuracy: 0.8498 - val_loss: 0.7628 - val_accuracy: 0.8415\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7092 - accuracy: 0.8514 - val_loss: 0.7520 - val_accuracy: 0.8446\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7121 - accuracy: 0.8509 - val_loss: 0.6972 - val_accuracy: 0.8596\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7080 - accuracy: 0.8510 - val_loss: 0.7391 - val_accuracy: 0.8496\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7104 - accuracy: 0.8504 - val_loss: 0.7067 - val_accuracy: 0.8585\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7105 - accuracy: 0.8503 - val_loss: 0.7202 - val_accuracy: 0.8523\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7137 - accuracy: 0.8492 - val_loss: 0.6930 - val_accuracy: 0.8584\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7006 - accuracy: 0.8524 - val_loss: 0.7212 - val_accuracy: 0.8534\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7062 - accuracy: 0.8482 - val_loss: 0.7227 - val_accuracy: 0.8555\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7019 - accuracy: 0.8526 - val_loss: 0.7419 - val_accuracy: 0.8459\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7026 - accuracy: 0.8527 - val_loss: 0.6824 - val_accuracy: 0.8638\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.7070 - accuracy: 0.8502 - val_loss: 0.7168 - val_accuracy: 0.8519\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7049 - accuracy: 0.8513 - val_loss: 0.7135 - val_accuracy: 0.8525\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7029 - accuracy: 0.8507 - val_loss: 0.7160 - val_accuracy: 0.8502\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6932 - accuracy: 0.8549 - val_loss: 0.7443 - val_accuracy: 0.8487\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7012 - accuracy: 0.8512 - val_loss: 0.6823 - val_accuracy: 0.8636\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6823 - accuracy: 0.8636\n",
            "\n",
            "Test result: 86.360 loss: 0.682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAmQeCnCd0h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}