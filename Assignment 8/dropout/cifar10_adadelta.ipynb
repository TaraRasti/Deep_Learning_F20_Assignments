{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-adadelta.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO50nBUmdXn+jKLjV0ftuOu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaraRasti/Deep_Learning_F20_Assignments/blob/master/Assignment%208/dropout/cifar10_adadelta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bM1QWq0ISwJ",
        "outputId": "3a5701fc-55f2-4125-9a6b-61c4daf3ecd7"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "#z-score\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "\n",
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)\n",
        "\n",
        "baseMapNum = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "#training\n",
        "batch_size = 64\n",
        "epochs=25\n",
        "opt_rms = keras.optimizers.Adadelta(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep75.h5')\n",
        "\n",
        "opt_rms = keras.optimizers.Adadelta(lr=0.0005,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep100.h5')\n",
        "\n",
        "opt_rms = keras.optimizers.Adadelta(lr=0.0003,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep125.h5')\n",
        "\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From <ipython-input-1-dc3f00551179>:83: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 5.2666 - accuracy: 0.1103 - val_loss: 3.4688 - val_accuracy: 0.1523\n",
            "Epoch 2/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 4.7051 - accuracy: 0.1385 - val_loss: 3.2596 - val_accuracy: 0.1993\n",
            "Epoch 3/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 4.5100 - accuracy: 0.1565 - val_loss: 3.1414 - val_accuracy: 0.2295\n",
            "Epoch 4/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 4.3763 - accuracy: 0.1750 - val_loss: 3.0653 - val_accuracy: 0.2553\n",
            "Epoch 5/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 4.2714 - accuracy: 0.1864 - val_loss: 3.0030 - val_accuracy: 0.2710\n",
            "Epoch 6/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 4.1976 - accuracy: 0.1986 - val_loss: 2.9562 - val_accuracy: 0.2862\n",
            "Epoch 7/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 4.1494 - accuracy: 0.2039 - val_loss: 2.9157 - val_accuracy: 0.2988\n",
            "Epoch 8/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 4.0777 - accuracy: 0.2143 - val_loss: 2.8796 - val_accuracy: 0.3094\n",
            "Epoch 9/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 4.0283 - accuracy: 0.2183 - val_loss: 2.8484 - val_accuracy: 0.3187\n",
            "Epoch 10/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.9946 - accuracy: 0.2264 - val_loss: 2.8211 - val_accuracy: 0.3279\n",
            "Epoch 11/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.9518 - accuracy: 0.2283 - val_loss: 2.7978 - val_accuracy: 0.3355\n",
            "Epoch 12/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.9119 - accuracy: 0.2351 - val_loss: 2.7722 - val_accuracy: 0.3448\n",
            "Epoch 13/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.8673 - accuracy: 0.2395 - val_loss: 2.7534 - val_accuracy: 0.3520\n",
            "Epoch 14/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.8358 - accuracy: 0.2461 - val_loss: 2.7321 - val_accuracy: 0.3578\n",
            "Epoch 15/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.8174 - accuracy: 0.2484 - val_loss: 2.7167 - val_accuracy: 0.3647\n",
            "Epoch 16/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.7717 - accuracy: 0.2532 - val_loss: 2.7003 - val_accuracy: 0.3689\n",
            "Epoch 17/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.7467 - accuracy: 0.2542 - val_loss: 2.6844 - val_accuracy: 0.3740\n",
            "Epoch 18/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.7200 - accuracy: 0.2606 - val_loss: 2.6704 - val_accuracy: 0.3775\n",
            "Epoch 19/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.7009 - accuracy: 0.2632 - val_loss: 2.6561 - val_accuracy: 0.3825\n",
            "Epoch 20/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.6707 - accuracy: 0.2653 - val_loss: 2.6422 - val_accuracy: 0.3861\n",
            "Epoch 21/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.6419 - accuracy: 0.2677 - val_loss: 2.6310 - val_accuracy: 0.3894\n",
            "Epoch 22/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.6237 - accuracy: 0.2720 - val_loss: 2.6167 - val_accuracy: 0.3941\n",
            "Epoch 23/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.6054 - accuracy: 0.2707 - val_loss: 2.6077 - val_accuracy: 0.3948\n",
            "Epoch 24/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.5698 - accuracy: 0.2748 - val_loss: 2.5989 - val_accuracy: 0.3971\n",
            "Epoch 25/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.5440 - accuracy: 0.2793 - val_loss: 2.5895 - val_accuracy: 0.3993\n",
            "Epoch 26/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.5415 - accuracy: 0.2763 - val_loss: 2.5793 - val_accuracy: 0.4042\n",
            "Epoch 27/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.5091 - accuracy: 0.2834 - val_loss: 2.5684 - val_accuracy: 0.4068\n",
            "Epoch 28/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.4740 - accuracy: 0.2910 - val_loss: 2.5599 - val_accuracy: 0.4081\n",
            "Epoch 29/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.4750 - accuracy: 0.2866 - val_loss: 2.5526 - val_accuracy: 0.4100\n",
            "Epoch 30/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.4388 - accuracy: 0.2898 - val_loss: 2.5445 - val_accuracy: 0.4127\n",
            "Epoch 31/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.4236 - accuracy: 0.2949 - val_loss: 2.5380 - val_accuracy: 0.4150\n",
            "Epoch 32/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.4184 - accuracy: 0.2940 - val_loss: 2.5296 - val_accuracy: 0.4184\n",
            "Epoch 33/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.3821 - accuracy: 0.2977 - val_loss: 2.5225 - val_accuracy: 0.4193\n",
            "Epoch 34/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.3839 - accuracy: 0.2928 - val_loss: 2.5150 - val_accuracy: 0.4212\n",
            "Epoch 35/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.3722 - accuracy: 0.2999 - val_loss: 2.5091 - val_accuracy: 0.4232\n",
            "Epoch 36/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.3522 - accuracy: 0.3001 - val_loss: 2.5041 - val_accuracy: 0.4246\n",
            "Epoch 37/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.3412 - accuracy: 0.3046 - val_loss: 2.4962 - val_accuracy: 0.4257\n",
            "Epoch 38/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.3167 - accuracy: 0.3044 - val_loss: 2.4909 - val_accuracy: 0.4276\n",
            "Epoch 39/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.2935 - accuracy: 0.3060 - val_loss: 2.4859 - val_accuracy: 0.4298\n",
            "Epoch 40/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.2728 - accuracy: 0.3093 - val_loss: 2.4777 - val_accuracy: 0.4325\n",
            "Epoch 41/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.2854 - accuracy: 0.3077 - val_loss: 2.4716 - val_accuracy: 0.4340\n",
            "Epoch 42/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.2508 - accuracy: 0.3096 - val_loss: 2.4667 - val_accuracy: 0.4343\n",
            "Epoch 43/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.2549 - accuracy: 0.3164 - val_loss: 2.4629 - val_accuracy: 0.4365\n",
            "Epoch 44/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.2342 - accuracy: 0.3136 - val_loss: 2.4572 - val_accuracy: 0.4375\n",
            "Epoch 45/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.2368 - accuracy: 0.3160 - val_loss: 2.4523 - val_accuracy: 0.4395\n",
            "Epoch 46/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.2056 - accuracy: 0.3177 - val_loss: 2.4468 - val_accuracy: 0.4402\n",
            "Epoch 47/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.1864 - accuracy: 0.3215 - val_loss: 2.4403 - val_accuracy: 0.4399\n",
            "Epoch 48/75\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 3.1835 - accuracy: 0.3195 - val_loss: 2.4374 - val_accuracy: 0.4412\n",
            "Epoch 49/75\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 3.1823 - accuracy: 0.3223 - val_loss: 2.4329 - val_accuracy: 0.4427\n",
            "Epoch 50/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.1512 - accuracy: 0.3244 - val_loss: 2.4275 - val_accuracy: 0.4433\n",
            "Epoch 51/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.1545 - accuracy: 0.3263 - val_loss: 2.4221 - val_accuracy: 0.4459\n",
            "Epoch 52/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.1461 - accuracy: 0.3244 - val_loss: 2.4199 - val_accuracy: 0.4463\n",
            "Epoch 53/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.1213 - accuracy: 0.3255 - val_loss: 2.4144 - val_accuracy: 0.4462\n",
            "Epoch 54/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.1192 - accuracy: 0.3283 - val_loss: 2.4104 - val_accuracy: 0.4481\n",
            "Epoch 55/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.0982 - accuracy: 0.3292 - val_loss: 2.4084 - val_accuracy: 0.4490\n",
            "Epoch 56/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.0947 - accuracy: 0.3314 - val_loss: 2.4034 - val_accuracy: 0.4496\n",
            "Epoch 57/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.0923 - accuracy: 0.3331 - val_loss: 2.4024 - val_accuracy: 0.4502\n",
            "Epoch 58/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.0722 - accuracy: 0.3367 - val_loss: 2.3965 - val_accuracy: 0.4529\n",
            "Epoch 59/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.0588 - accuracy: 0.3376 - val_loss: 2.3925 - val_accuracy: 0.4530\n",
            "Epoch 60/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.0514 - accuracy: 0.3366 - val_loss: 2.3888 - val_accuracy: 0.4527\n",
            "Epoch 61/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.0396 - accuracy: 0.3413 - val_loss: 2.3867 - val_accuracy: 0.4551\n",
            "Epoch 62/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.0447 - accuracy: 0.3387 - val_loss: 2.3825 - val_accuracy: 0.4573\n",
            "Epoch 63/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.0226 - accuracy: 0.3426 - val_loss: 2.3784 - val_accuracy: 0.4574\n",
            "Epoch 64/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 3.0116 - accuracy: 0.3423 - val_loss: 2.3773 - val_accuracy: 0.4573\n",
            "Epoch 65/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.0230 - accuracy: 0.3394 - val_loss: 2.3722 - val_accuracy: 0.4594\n",
            "Epoch 66/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.0164 - accuracy: 0.3388 - val_loss: 2.3721 - val_accuracy: 0.4589\n",
            "Epoch 67/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.9985 - accuracy: 0.3431 - val_loss: 2.3668 - val_accuracy: 0.4604\n",
            "Epoch 68/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.9983 - accuracy: 0.3442 - val_loss: 2.3635 - val_accuracy: 0.4604\n",
            "Epoch 69/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.9750 - accuracy: 0.3494 - val_loss: 2.3602 - val_accuracy: 0.4623\n",
            "Epoch 70/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.9725 - accuracy: 0.3478 - val_loss: 2.3608 - val_accuracy: 0.4623\n",
            "Epoch 71/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.9827 - accuracy: 0.3472 - val_loss: 2.3551 - val_accuracy: 0.4637\n",
            "Epoch 72/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.9586 - accuracy: 0.3484 - val_loss: 2.3501 - val_accuracy: 0.4636\n",
            "Epoch 73/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.9459 - accuracy: 0.3509 - val_loss: 2.3468 - val_accuracy: 0.4633\n",
            "Epoch 74/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.9441 - accuracy: 0.3529 - val_loss: 2.3470 - val_accuracy: 0.4645\n",
            "Epoch 75/75\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.9440 - accuracy: 0.3506 - val_loss: 2.3430 - val_accuracy: 0.4659\n",
            "Epoch 1/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.9363 - accuracy: 0.3549 - val_loss: 2.3421 - val_accuracy: 0.4650\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.9309 - accuracy: 0.3548 - val_loss: 2.3387 - val_accuracy: 0.4666\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.9275 - accuracy: 0.3559 - val_loss: 2.3363 - val_accuracy: 0.4666\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.9064 - accuracy: 0.3599 - val_loss: 2.3359 - val_accuracy: 0.4662\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.9171 - accuracy: 0.3561 - val_loss: 2.3357 - val_accuracy: 0.4663\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.9141 - accuracy: 0.3608 - val_loss: 2.3319 - val_accuracy: 0.4669\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.9082 - accuracy: 0.3592 - val_loss: 2.3309 - val_accuracy: 0.4677\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.8953 - accuracy: 0.3590 - val_loss: 2.3303 - val_accuracy: 0.4678\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.9085 - accuracy: 0.3569 - val_loss: 2.3287 - val_accuracy: 0.4692\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8978 - accuracy: 0.3597 - val_loss: 2.3284 - val_accuracy: 0.4687\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8942 - accuracy: 0.3583 - val_loss: 2.3274 - val_accuracy: 0.4702\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.8984 - accuracy: 0.3585 - val_loss: 2.3253 - val_accuracy: 0.4693\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8784 - accuracy: 0.3618 - val_loss: 2.3237 - val_accuracy: 0.4706\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8745 - accuracy: 0.3639 - val_loss: 2.3244 - val_accuracy: 0.4708\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.8777 - accuracy: 0.3610 - val_loss: 2.3221 - val_accuracy: 0.4727\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8760 - accuracy: 0.3643 - val_loss: 2.3186 - val_accuracy: 0.4738\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8890 - accuracy: 0.3633 - val_loss: 2.3183 - val_accuracy: 0.4736\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8709 - accuracy: 0.3651 - val_loss: 2.3169 - val_accuracy: 0.4737\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8753 - accuracy: 0.3625 - val_loss: 2.3165 - val_accuracy: 0.4743\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8682 - accuracy: 0.3660 - val_loss: 2.3149 - val_accuracy: 0.4754\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8649 - accuracy: 0.3648 - val_loss: 2.3125 - val_accuracy: 0.4758\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8577 - accuracy: 0.3679 - val_loss: 2.3120 - val_accuracy: 0.4759\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8588 - accuracy: 0.3660 - val_loss: 2.3140 - val_accuracy: 0.4754\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8470 - accuracy: 0.3693 - val_loss: 2.3084 - val_accuracy: 0.4758\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.8525 - accuracy: 0.3679 - val_loss: 2.3093 - val_accuracy: 0.4768\n",
            "Epoch 1/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8511 - accuracy: 0.3697 - val_loss: 2.3062 - val_accuracy: 0.4779\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.8496 - accuracy: 0.3703 - val_loss: 2.3080 - val_accuracy: 0.4777\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.8421 - accuracy: 0.3688 - val_loss: 2.3072 - val_accuracy: 0.4779\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8481 - accuracy: 0.3697 - val_loss: 2.3046 - val_accuracy: 0.4777\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8383 - accuracy: 0.3763 - val_loss: 2.3032 - val_accuracy: 0.4778\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.8400 - accuracy: 0.3714 - val_loss: 2.3029 - val_accuracy: 0.4784\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8471 - accuracy: 0.3724 - val_loss: 2.3013 - val_accuracy: 0.4792\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8317 - accuracy: 0.3708 - val_loss: 2.3028 - val_accuracy: 0.4786\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.8431 - accuracy: 0.3704 - val_loss: 2.3009 - val_accuracy: 0.4784\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8422 - accuracy: 0.3700 - val_loss: 2.3015 - val_accuracy: 0.4791\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8234 - accuracy: 0.3708 - val_loss: 2.2992 - val_accuracy: 0.4796\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8233 - accuracy: 0.3701 - val_loss: 2.2986 - val_accuracy: 0.4810\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8330 - accuracy: 0.3733 - val_loss: 2.2963 - val_accuracy: 0.4801\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8256 - accuracy: 0.3753 - val_loss: 2.2986 - val_accuracy: 0.4804\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8320 - accuracy: 0.3740 - val_loss: 2.2961 - val_accuracy: 0.4811\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8150 - accuracy: 0.3769 - val_loss: 2.2949 - val_accuracy: 0.4804\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8292 - accuracy: 0.3757 - val_loss: 2.2978 - val_accuracy: 0.4810\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8303 - accuracy: 0.3726 - val_loss: 2.2950 - val_accuracy: 0.4812\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.8084 - accuracy: 0.3763 - val_loss: 2.2935 - val_accuracy: 0.4816\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 2.8287 - accuracy: 0.3723 - val_loss: 2.2923 - val_accuracy: 0.4817\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8207 - accuracy: 0.3780 - val_loss: 2.2916 - val_accuracy: 0.4810\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8118 - accuracy: 0.3774 - val_loss: 2.2920 - val_accuracy: 0.4822\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.8009 - accuracy: 0.3779 - val_loss: 2.2898 - val_accuracy: 0.4818\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8087 - accuracy: 0.3773 - val_loss: 2.2904 - val_accuracy: 0.4827\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 2.8100 - accuracy: 0.3757 - val_loss: 2.2866 - val_accuracy: 0.4837\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.2866 - accuracy: 0.4837\n",
            "\n",
            "Test result: 48.370 loss: 2.287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-GxpDbxIafu"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}