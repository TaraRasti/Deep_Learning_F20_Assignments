{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Users/taraapple/Desktop/train.csv')\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('/Users/taraapple/Desktop/test.csv')\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label'].values\n",
    "X_train = train_df.drop(['label'],1).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "27995       0       0       0       0       0       0       0       0       0   \n",
       "27996       0       0       0       0       0       0       0       0       0   \n",
       "27997       0       0       0       0       0       0       0       0       0   \n",
       "27998       0       0       0       0       0       0       0       0       0   \n",
       "27999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "27995       0  ...         0         0         0         0         0   \n",
       "27996       0  ...         0         0         0         0         0   \n",
       "27997       0  ...         0         0         0         0         0   \n",
       "27998       0  ...         0         0         0         0         0   \n",
       "27999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27995         0         0         0         0         0  \n",
       "27996         0         0         0         0         0  \n",
       "27997         0         0         0         0         0  \n",
       "27998         0         0         0         0         0  \n",
       "27999         0         0         0         0         0  \n",
       "\n",
       "[28000 rows x 784 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-740606f2ed64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#X_test = test_df.drop(['label'],1).values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "y_test = test_df['label'].values\n",
    "#X_test = test_df.drop(['label'],1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
      "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    " \n",
    "mlp = MLP()\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 5\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.item(), float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/35700 (0%)]\tLoss: 8.159407\t Accuracy:18.750%\n",
      "Epoch : 0 [1600/35700 (4%)]\tLoss: 0.227379\t Accuracy:69.792%\n",
      "Epoch : 0 [3200/35700 (9%)]\tLoss: 0.521355\t Accuracy:77.970%\n",
      "Epoch : 0 [4800/35700 (13%)]\tLoss: 0.309238\t Accuracy:81.250%\n",
      "Epoch : 0 [6400/35700 (18%)]\tLoss: 0.544148\t Accuracy:83.520%\n",
      "Epoch : 0 [8000/35700 (22%)]\tLoss: 0.220697\t Accuracy:84.935%\n",
      "Epoch : 0 [9600/35700 (27%)]\tLoss: 0.367417\t Accuracy:85.725%\n",
      "Epoch : 0 [11200/35700 (31%)]\tLoss: 0.654621\t Accuracy:86.565%\n",
      "Epoch : 0 [12800/35700 (36%)]\tLoss: 0.742725\t Accuracy:87.149%\n",
      "Epoch : 0 [14400/35700 (40%)]\tLoss: 0.252580\t Accuracy:87.694%\n",
      "Epoch : 0 [16000/35700 (45%)]\tLoss: 0.203498\t Accuracy:88.074%\n",
      "Epoch : 0 [17600/35700 (49%)]\tLoss: 0.285547\t Accuracy:88.561%\n",
      "Epoch : 0 [19200/35700 (54%)]\tLoss: 0.091625\t Accuracy:88.878%\n",
      "Epoch : 0 [20800/35700 (58%)]\tLoss: 0.561206\t Accuracy:89.113%\n",
      "Epoch : 0 [22400/35700 (63%)]\tLoss: 0.442160\t Accuracy:89.279%\n",
      "Epoch : 0 [24000/35700 (67%)]\tLoss: 0.143203\t Accuracy:89.531%\n",
      "Epoch : 0 [25600/35700 (72%)]\tLoss: 0.265539\t Accuracy:89.786%\n",
      "Epoch : 0 [27200/35700 (76%)]\tLoss: 0.029722\t Accuracy:89.953%\n",
      "Epoch : 0 [28800/35700 (81%)]\tLoss: 0.068173\t Accuracy:90.139%\n",
      "Epoch : 0 [30400/35700 (85%)]\tLoss: 0.277356\t Accuracy:90.365%\n",
      "Epoch : 0 [32000/35700 (90%)]\tLoss: 0.038641\t Accuracy:90.534%\n",
      "Epoch : 0 [33600/35700 (94%)]\tLoss: 0.199879\t Accuracy:90.667%\n",
      "Epoch : 0 [35200/35700 (99%)]\tLoss: 0.128987\t Accuracy:90.821%\n",
      "Epoch : 1 [0/35700 (0%)]\tLoss: 0.508574\t Accuracy:87.500%\n",
      "Epoch : 1 [1600/35700 (4%)]\tLoss: 0.300474\t Accuracy:93.811%\n",
      "Epoch : 1 [3200/35700 (9%)]\tLoss: 0.025823\t Accuracy:93.936%\n",
      "Epoch : 1 [4800/35700 (13%)]\tLoss: 0.161789\t Accuracy:94.412%\n",
      "Epoch : 1 [6400/35700 (18%)]\tLoss: 0.330012\t Accuracy:94.450%\n",
      "Epoch : 1 [8000/35700 (22%)]\tLoss: 0.049553\t Accuracy:94.783%\n",
      "Epoch : 1 [9600/35700 (27%)]\tLoss: 0.077605\t Accuracy:94.809%\n",
      "Epoch : 1 [11200/35700 (31%)]\tLoss: 0.208420\t Accuracy:94.979%\n",
      "Epoch : 1 [12800/35700 (36%)]\tLoss: 0.277520\t Accuracy:94.966%\n",
      "Epoch : 1 [14400/35700 (40%)]\tLoss: 0.175708\t Accuracy:94.990%\n",
      "Epoch : 1 [16000/35700 (45%)]\tLoss: 0.100109\t Accuracy:95.054%\n",
      "Epoch : 1 [17600/35700 (49%)]\tLoss: 0.033626\t Accuracy:95.060%\n",
      "Epoch : 1 [19200/35700 (54%)]\tLoss: 0.087742\t Accuracy:95.128%\n",
      "Epoch : 1 [20800/35700 (58%)]\tLoss: 0.170386\t Accuracy:95.089%\n",
      "Epoch : 1 [22400/35700 (63%)]\tLoss: 0.221282\t Accuracy:95.096%\n",
      "Epoch : 1 [24000/35700 (67%)]\tLoss: 0.078843\t Accuracy:95.127%\n",
      "Epoch : 1 [25600/35700 (72%)]\tLoss: 0.105612\t Accuracy:95.151%\n",
      "Epoch : 1 [27200/35700 (76%)]\tLoss: 0.020000\t Accuracy:95.197%\n",
      "Epoch : 1 [28800/35700 (81%)]\tLoss: 0.015239\t Accuracy:95.228%\n",
      "Epoch : 1 [30400/35700 (85%)]\tLoss: 0.274588\t Accuracy:95.265%\n",
      "Epoch : 1 [32000/35700 (90%)]\tLoss: 0.039525\t Accuracy:95.283%\n",
      "Epoch : 1 [33600/35700 (94%)]\tLoss: 0.309984\t Accuracy:95.320%\n",
      "Epoch : 1 [35200/35700 (99%)]\tLoss: 0.102010\t Accuracy:95.345%\n",
      "Epoch : 2 [0/35700 (0%)]\tLoss: 0.271487\t Accuracy:90.625%\n",
      "Epoch : 2 [1600/35700 (4%)]\tLoss: 0.138746\t Accuracy:95.282%\n",
      "Epoch : 2 [3200/35700 (9%)]\tLoss: 0.035784\t Accuracy:95.575%\n",
      "Epoch : 2 [4800/35700 (13%)]\tLoss: 0.047619\t Accuracy:95.882%\n",
      "Epoch : 2 [6400/35700 (18%)]\tLoss: 0.185219\t Accuracy:95.927%\n",
      "Epoch : 2 [8000/35700 (22%)]\tLoss: 0.234343\t Accuracy:95.891%\n",
      "Epoch : 2 [9600/35700 (27%)]\tLoss: 0.289730\t Accuracy:95.681%\n",
      "Epoch : 2 [11200/35700 (31%)]\tLoss: 0.171849\t Accuracy:95.664%\n",
      "Epoch : 2 [12800/35700 (36%)]\tLoss: 0.338558\t Accuracy:95.729%\n",
      "Epoch : 2 [14400/35700 (40%)]\tLoss: 0.017619\t Accuracy:95.718%\n",
      "Epoch : 2 [16000/35700 (45%)]\tLoss: 0.002374\t Accuracy:95.758%\n",
      "Epoch : 2 [17600/35700 (49%)]\tLoss: 0.125883\t Accuracy:95.741%\n",
      "Epoch : 2 [19200/35700 (54%)]\tLoss: 0.042546\t Accuracy:95.767%\n",
      "Epoch : 2 [20800/35700 (58%)]\tLoss: 0.111931\t Accuracy:95.781%\n",
      "Epoch : 2 [22400/35700 (63%)]\tLoss: 0.187515\t Accuracy:95.805%\n",
      "Epoch : 2 [24000/35700 (67%)]\tLoss: 0.009045\t Accuracy:95.835%\n",
      "Epoch : 2 [25600/35700 (72%)]\tLoss: 0.189138\t Accuracy:95.810%\n",
      "Epoch : 2 [27200/35700 (76%)]\tLoss: 0.018841\t Accuracy:95.817%\n",
      "Epoch : 2 [28800/35700 (81%)]\tLoss: 0.011493\t Accuracy:95.838%\n",
      "Epoch : 2 [30400/35700 (85%)]\tLoss: 0.062143\t Accuracy:95.869%\n",
      "Epoch : 2 [32000/35700 (90%)]\tLoss: 0.025306\t Accuracy:95.879%\n",
      "Epoch : 2 [33600/35700 (94%)]\tLoss: 0.079747\t Accuracy:95.941%\n",
      "Epoch : 2 [35200/35700 (99%)]\tLoss: 0.176043\t Accuracy:95.936%\n",
      "Epoch : 3 [0/35700 (0%)]\tLoss: 0.117884\t Accuracy:96.875%\n",
      "Epoch : 3 [1600/35700 (4%)]\tLoss: 0.069569\t Accuracy:96.630%\n",
      "Epoch : 3 [3200/35700 (9%)]\tLoss: 0.141060\t Accuracy:96.349%\n",
      "Epoch : 3 [4800/35700 (13%)]\tLoss: 0.065848\t Accuracy:96.358%\n",
      "Epoch : 3 [6400/35700 (18%)]\tLoss: 0.488225\t Accuracy:96.455%\n",
      "Epoch : 3 [8000/35700 (22%)]\tLoss: 0.040834\t Accuracy:96.427%\n",
      "Epoch : 3 [9600/35700 (27%)]\tLoss: 0.407790\t Accuracy:96.346%\n",
      "Epoch : 3 [11200/35700 (31%)]\tLoss: 0.049907\t Accuracy:96.403%\n",
      "Epoch : 3 [12800/35700 (36%)]\tLoss: 0.088684\t Accuracy:96.353%\n",
      "Epoch : 3 [14400/35700 (40%)]\tLoss: 0.275719\t Accuracy:96.307%\n",
      "Epoch : 3 [16000/35700 (45%)]\tLoss: 0.009304\t Accuracy:96.357%\n",
      "Epoch : 3 [17600/35700 (49%)]\tLoss: 0.018751\t Accuracy:96.370%\n",
      "Epoch : 3 [19200/35700 (54%)]\tLoss: 0.019976\t Accuracy:96.443%\n",
      "Epoch : 3 [20800/35700 (58%)]\tLoss: 0.063570\t Accuracy:96.453%\n",
      "Epoch : 3 [22400/35700 (63%)]\tLoss: 0.108678\t Accuracy:96.469%\n",
      "Epoch : 3 [24000/35700 (67%)]\tLoss: 0.039449\t Accuracy:96.505%\n",
      "Epoch : 3 [25600/35700 (72%)]\tLoss: 0.002833\t Accuracy:96.543%\n",
      "Epoch : 3 [27200/35700 (76%)]\tLoss: 0.004425\t Accuracy:96.537%\n",
      "Epoch : 3 [28800/35700 (81%)]\tLoss: 0.004577\t Accuracy:96.500%\n",
      "Epoch : 3 [30400/35700 (85%)]\tLoss: 0.100477\t Accuracy:96.523%\n",
      "Epoch : 3 [32000/35700 (90%)]\tLoss: 0.022589\t Accuracy:96.528%\n",
      "Epoch : 3 [33600/35700 (94%)]\tLoss: 0.210180\t Accuracy:96.512%\n",
      "Epoch : 3 [35200/35700 (99%)]\tLoss: 0.094193\t Accuracy:96.512%\n",
      "Epoch : 4 [0/35700 (0%)]\tLoss: 0.127653\t Accuracy:93.750%\n",
      "Epoch : 4 [1600/35700 (4%)]\tLoss: 0.062088\t Accuracy:96.017%\n",
      "Epoch : 4 [3200/35700 (9%)]\tLoss: 0.039836\t Accuracy:96.442%\n",
      "Epoch : 4 [4800/35700 (13%)]\tLoss: 0.065472\t Accuracy:96.523%\n",
      "Epoch : 4 [6400/35700 (18%)]\tLoss: 0.134573\t Accuracy:96.440%\n",
      "Epoch : 4 [8000/35700 (22%)]\tLoss: 0.113591\t Accuracy:96.365%\n",
      "Epoch : 4 [9600/35700 (27%)]\tLoss: 0.293267\t Accuracy:96.294%\n",
      "Epoch : 4 [11200/35700 (31%)]\tLoss: 0.103458\t Accuracy:96.412%\n",
      "Epoch : 4 [12800/35700 (36%)]\tLoss: 0.271093\t Accuracy:96.439%\n",
      "Epoch : 4 [14400/35700 (40%)]\tLoss: 0.068249\t Accuracy:96.466%\n",
      "Epoch : 4 [16000/35700 (45%)]\tLoss: 0.006463\t Accuracy:96.495%\n",
      "Epoch : 4 [17600/35700 (49%)]\tLoss: 0.005502\t Accuracy:96.501%\n",
      "Epoch : 4 [19200/35700 (54%)]\tLoss: 0.172678\t Accuracy:96.563%\n",
      "Epoch : 4 [20800/35700 (58%)]\tLoss: 0.038741\t Accuracy:96.611%\n",
      "Epoch : 4 [22400/35700 (63%)]\tLoss: 0.039281\t Accuracy:96.674%\n",
      "Epoch : 4 [24000/35700 (67%)]\tLoss: 0.058698\t Accuracy:96.667%\n",
      "Epoch : 4 [25600/35700 (72%)]\tLoss: 0.101204\t Accuracy:96.711%\n",
      "Epoch : 4 [27200/35700 (76%)]\tLoss: 0.004383\t Accuracy:96.783%\n",
      "Epoch : 4 [28800/35700 (81%)]\tLoss: 0.003620\t Accuracy:96.785%\n",
      "Epoch : 4 [30400/35700 (85%)]\tLoss: 0.513681\t Accuracy:96.799%\n",
      "Epoch : 4 [32000/35700 (90%)]\tLoss: 0.026568\t Accuracy:96.803%\n",
      "Epoch : 4 [33600/35700 (94%)]\tLoss: 0.004583\t Accuracy:96.848%\n",
      "Epoch : 4 [35200/35700 (99%)]\tLoss: 0.147747\t Accuracy:96.858%\n"
     ]
    }
   ],
   "source": [
    "fit(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.955% \n"
     ]
    }
   ],
   "source": [
    "def evaluate(model):\n",
    "#model = mlp\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}% \".format( float(correct) / (len(test_loader)*BATCH_SIZE)))\n",
    "evaluate(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35700, 1, 28, 28])\n",
      "torch.Size([6300, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "torch_X_train = torch_X_train.view(-1, 1,28,28).float()\n",
    "torch_X_test = torch_X_test.view(-1,1,28,28).float()\n",
    "print(torch_X_train.shape)\n",
    "print(torch_X_test.shape)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.view(-1,3*3*64 )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    " \n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "it = iter(train_loader)\n",
    "X_batch, y_batch = next(it)\n",
    "print(cnn.forward(X_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/35700 (0%)]\tLoss: 24.555870\t Accuracy:9.375%\n",
      "Epoch : 0 [1600/35700 (4%)]\tLoss: 2.077325\t Accuracy:15.625%\n",
      "Epoch : 0 [3200/35700 (9%)]\tLoss: 1.375981\t Accuracy:25.557%\n",
      "Epoch : 0 [4800/35700 (13%)]\tLoss: 1.094583\t Accuracy:36.796%\n",
      "Epoch : 0 [6400/35700 (18%)]\tLoss: 0.967033\t Accuracy:45.072%\n",
      "Epoch : 0 [8000/35700 (22%)]\tLoss: 0.404181\t Accuracy:51.594%\n",
      "Epoch : 0 [9600/35700 (27%)]\tLoss: 0.678731\t Accuracy:55.845%\n",
      "Epoch : 0 [11200/35700 (31%)]\tLoss: 0.598726\t Accuracy:59.740%\n",
      "Epoch : 0 [12800/35700 (36%)]\tLoss: 0.935075\t Accuracy:62.765%\n",
      "Epoch : 0 [14400/35700 (40%)]\tLoss: 0.520798\t Accuracy:65.195%\n",
      "Epoch : 0 [16000/35700 (45%)]\tLoss: 0.327560\t Accuracy:67.278%\n",
      "Epoch : 0 [17600/35700 (49%)]\tLoss: 0.428962\t Accuracy:69.215%\n",
      "Epoch : 0 [19200/35700 (54%)]\tLoss: 0.450609\t Accuracy:70.825%\n",
      "Epoch : 0 [20800/35700 (58%)]\tLoss: 0.256112\t Accuracy:72.206%\n",
      "Epoch : 0 [22400/35700 (63%)]\tLoss: 0.646318\t Accuracy:73.337%\n",
      "Epoch : 0 [24000/35700 (67%)]\tLoss: 0.175919\t Accuracy:74.451%\n",
      "Epoch : 0 [25600/35700 (72%)]\tLoss: 0.475935\t Accuracy:75.234%\n",
      "Epoch : 0 [27200/35700 (76%)]\tLoss: 0.297731\t Accuracy:76.164%\n",
      "Epoch : 0 [28800/35700 (81%)]\tLoss: 0.117922\t Accuracy:76.963%\n",
      "Epoch : 0 [30400/35700 (85%)]\tLoss: 0.634124\t Accuracy:77.655%\n",
      "Epoch : 0 [32000/35700 (90%)]\tLoss: 0.118670\t Accuracy:78.337%\n",
      "Epoch : 0 [33600/35700 (94%)]\tLoss: 0.400029\t Accuracy:78.958%\n",
      "Epoch : 0 [35200/35700 (99%)]\tLoss: 0.195105\t Accuracy:79.547%\n",
      "Epoch : 1 [0/35700 (0%)]\tLoss: 0.353379\t Accuracy:87.500%\n",
      "Epoch : 1 [1600/35700 (4%)]\tLoss: 0.103739\t Accuracy:91.299%\n",
      "Epoch : 1 [3200/35700 (9%)]\tLoss: 0.243762\t Accuracy:91.399%\n",
      "Epoch : 1 [4800/35700 (13%)]\tLoss: 0.441690\t Accuracy:91.184%\n",
      "Epoch : 1 [6400/35700 (18%)]\tLoss: 0.401809\t Accuracy:91.496%\n",
      "Epoch : 1 [8000/35700 (22%)]\tLoss: 0.209462\t Accuracy:91.559%\n",
      "Epoch : 1 [9600/35700 (27%)]\tLoss: 0.516627\t Accuracy:91.632%\n",
      "Epoch : 1 [11200/35700 (31%)]\tLoss: 0.329188\t Accuracy:91.658%\n",
      "Epoch : 1 [12800/35700 (36%)]\tLoss: 0.411672\t Accuracy:91.856%\n",
      "Epoch : 1 [14400/35700 (40%)]\tLoss: 0.126287\t Accuracy:91.942%\n",
      "Epoch : 1 [16000/35700 (45%)]\tLoss: 0.318054\t Accuracy:92.053%\n",
      "Epoch : 1 [17600/35700 (49%)]\tLoss: 0.363246\t Accuracy:92.077%\n",
      "Epoch : 1 [19200/35700 (54%)]\tLoss: 0.099030\t Accuracy:92.190%\n",
      "Epoch : 1 [20800/35700 (58%)]\tLoss: 0.273068\t Accuracy:92.248%\n",
      "Epoch : 1 [22400/35700 (63%)]\tLoss: 0.409052\t Accuracy:92.288%\n",
      "Epoch : 1 [24000/35700 (67%)]\tLoss: 0.273097\t Accuracy:92.369%\n",
      "Epoch : 1 [25600/35700 (72%)]\tLoss: 0.207048\t Accuracy:92.396%\n",
      "Epoch : 1 [27200/35700 (76%)]\tLoss: 0.162847\t Accuracy:92.501%\n",
      "Epoch : 1 [28800/35700 (81%)]\tLoss: 0.032753\t Accuracy:92.564%\n",
      "Epoch : 1 [30400/35700 (85%)]\tLoss: 0.412759\t Accuracy:92.629%\n",
      "Epoch : 1 [32000/35700 (90%)]\tLoss: 0.218973\t Accuracy:92.664%\n",
      "Epoch : 1 [33600/35700 (94%)]\tLoss: 0.155699\t Accuracy:92.724%\n",
      "Epoch : 1 [35200/35700 (99%)]\tLoss: 0.107340\t Accuracy:92.759%\n",
      "Epoch : 2 [0/35700 (0%)]\tLoss: 0.261810\t Accuracy:93.750%\n",
      "Epoch : 2 [1600/35700 (4%)]\tLoss: 0.075487\t Accuracy:93.627%\n",
      "Epoch : 2 [3200/35700 (9%)]\tLoss: 0.058391\t Accuracy:93.502%\n",
      "Epoch : 2 [4800/35700 (13%)]\tLoss: 0.302771\t Accuracy:93.419%\n",
      "Epoch : 2 [6400/35700 (18%)]\tLoss: 0.316242\t Accuracy:93.315%\n",
      "Epoch : 2 [8000/35700 (22%)]\tLoss: 0.193835\t Accuracy:93.464%\n",
      "Epoch : 2 [9600/35700 (27%)]\tLoss: 0.263312\t Accuracy:93.532%\n",
      "Epoch : 2 [11200/35700 (31%)]\tLoss: 0.105631\t Accuracy:93.670%\n",
      "Epoch : 2 [12800/35700 (36%)]\tLoss: 0.339793\t Accuracy:93.695%\n",
      "Epoch : 2 [14400/35700 (40%)]\tLoss: 0.103006\t Accuracy:93.743%\n",
      "Epoch : 2 [16000/35700 (45%)]\tLoss: 0.206746\t Accuracy:93.837%\n",
      "Epoch : 2 [17600/35700 (49%)]\tLoss: 0.348286\t Accuracy:93.880%\n",
      "Epoch : 2 [19200/35700 (54%)]\tLoss: 0.405609\t Accuracy:93.854%\n",
      "Epoch : 2 [20800/35700 (58%)]\tLoss: 0.161701\t Accuracy:93.875%\n",
      "Epoch : 2 [22400/35700 (63%)]\tLoss: 0.549416\t Accuracy:93.933%\n",
      "Epoch : 2 [24000/35700 (67%)]\tLoss: 0.110151\t Accuracy:93.891%\n",
      "Epoch : 2 [25600/35700 (72%)]\tLoss: 0.310611\t Accuracy:93.832%\n",
      "Epoch : 2 [27200/35700 (76%)]\tLoss: 0.372719\t Accuracy:93.882%\n",
      "Epoch : 2 [28800/35700 (81%)]\tLoss: 0.053019\t Accuracy:93.882%\n",
      "Epoch : 2 [30400/35700 (85%)]\tLoss: 0.271935\t Accuracy:93.918%\n",
      "Epoch : 2 [32000/35700 (90%)]\tLoss: 0.094667\t Accuracy:93.940%\n",
      "Epoch : 2 [33600/35700 (94%)]\tLoss: 0.219948\t Accuracy:93.964%\n",
      "Epoch : 2 [35200/35700 (99%)]\tLoss: 0.068769\t Accuracy:93.986%\n",
      "Epoch : 3 [0/35700 (0%)]\tLoss: 0.208876\t Accuracy:96.875%\n",
      "Epoch : 3 [1600/35700 (4%)]\tLoss: 0.082761\t Accuracy:94.179%\n",
      "Epoch : 3 [3200/35700 (9%)]\tLoss: 0.086737\t Accuracy:94.585%\n",
      "Epoch : 3 [4800/35700 (13%)]\tLoss: 0.088312\t Accuracy:94.536%\n",
      "Epoch : 3 [6400/35700 (18%)]\tLoss: 0.366274\t Accuracy:94.527%\n",
      "Epoch : 3 [8000/35700 (22%)]\tLoss: 0.239688\t Accuracy:94.522%\n",
      "Epoch : 3 [9600/35700 (27%)]\tLoss: 0.139011\t Accuracy:94.518%\n",
      "Epoch : 3 [11200/35700 (31%)]\tLoss: 0.118067\t Accuracy:94.623%\n",
      "Epoch : 3 [12800/35700 (36%)]\tLoss: 0.120630\t Accuracy:94.568%\n",
      "Epoch : 3 [14400/35700 (40%)]\tLoss: 0.040948\t Accuracy:94.720%\n",
      "Epoch : 3 [16000/35700 (45%)]\tLoss: 0.134726\t Accuracy:94.792%\n",
      "Epoch : 3 [17600/35700 (49%)]\tLoss: 0.137147\t Accuracy:94.737%\n",
      "Epoch : 3 [19200/35700 (54%)]\tLoss: 0.145169\t Accuracy:94.774%\n",
      "Epoch : 3 [20800/35700 (58%)]\tLoss: 0.340374\t Accuracy:94.777%\n",
      "Epoch : 3 [22400/35700 (63%)]\tLoss: 0.479908\t Accuracy:94.766%\n",
      "Epoch : 3 [24000/35700 (67%)]\tLoss: 0.014728\t Accuracy:94.745%\n",
      "Epoch : 3 [25600/35700 (72%)]\tLoss: 0.157248\t Accuracy:94.690%\n",
      "Epoch : 3 [27200/35700 (76%)]\tLoss: 0.011737\t Accuracy:94.705%\n",
      "Epoch : 3 [28800/35700 (81%)]\tLoss: 0.013817\t Accuracy:94.669%\n",
      "Epoch : 3 [30400/35700 (85%)]\tLoss: 0.102975\t Accuracy:94.647%\n",
      "Epoch : 3 [32000/35700 (90%)]\tLoss: 0.028400\t Accuracy:94.662%\n",
      "Epoch : 3 [33600/35700 (94%)]\tLoss: 0.104761\t Accuracy:94.645%\n",
      "Epoch : 3 [35200/35700 (99%)]\tLoss: 0.234864\t Accuracy:94.698%\n",
      "Epoch : 4 [0/35700 (0%)]\tLoss: 0.344891\t Accuracy:90.625%\n",
      "Epoch : 4 [1600/35700 (4%)]\tLoss: 0.014263\t Accuracy:94.975%\n",
      "Epoch : 4 [3200/35700 (9%)]\tLoss: 0.025310\t Accuracy:95.514%\n",
      "Epoch : 4 [4800/35700 (13%)]\tLoss: 0.229612\t Accuracy:95.550%\n",
      "Epoch : 4 [6400/35700 (18%)]\tLoss: 0.232537\t Accuracy:95.305%\n",
      "Epoch : 4 [8000/35700 (22%)]\tLoss: 0.176236\t Accuracy:95.219%\n",
      "Epoch : 4 [9600/35700 (27%)]\tLoss: 0.110053\t Accuracy:95.141%\n",
      "Epoch : 4 [11200/35700 (31%)]\tLoss: 0.164282\t Accuracy:95.281%\n",
      "Epoch : 4 [12800/35700 (36%)]\tLoss: 0.148392\t Accuracy:95.114%\n",
      "Epoch : 4 [14400/35700 (40%)]\tLoss: 0.055449\t Accuracy:95.136%\n",
      "Epoch : 4 [16000/35700 (45%)]\tLoss: 0.041374\t Accuracy:95.135%\n",
      "Epoch : 4 [17600/35700 (49%)]\tLoss: 0.037454\t Accuracy:95.134%\n",
      "Epoch : 4 [19200/35700 (54%)]\tLoss: 0.106949\t Accuracy:95.185%\n",
      "Epoch : 4 [20800/35700 (58%)]\tLoss: 0.090482\t Accuracy:95.185%\n",
      "Epoch : 4 [22400/35700 (63%)]\tLoss: 0.088211\t Accuracy:95.194%\n",
      "Epoch : 4 [24000/35700 (67%)]\tLoss: 0.046911\t Accuracy:95.198%\n",
      "Epoch : 4 [25600/35700 (72%)]\tLoss: 0.472665\t Accuracy:95.166%\n",
      "Epoch : 4 [27200/35700 (76%)]\tLoss: 0.030168\t Accuracy:95.175%\n",
      "Epoch : 4 [28800/35700 (81%)]\tLoss: 0.022857\t Accuracy:95.224%\n",
      "Epoch : 4 [30400/35700 (85%)]\tLoss: 0.284763\t Accuracy:95.252%\n",
      "Epoch : 4 [32000/35700 (90%)]\tLoss: 0.047248\t Accuracy:95.258%\n",
      "Epoch : 4 [33600/35700 (94%)]\tLoss: 0.341576\t Accuracy:95.243%\n",
      "Epoch : 4 [35200/35700 (99%)]\tLoss: 0.229549\t Accuracy:95.203%\n"
     ]
    }
   ],
   "source": [
    "fit(cnn,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.952% \n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import utils \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/taraapple/Desktop/train.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/taraapple/Desktop/test.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "27995       0       0       0       0       0       0       0       0       0   \n",
       "27996       0       0       0       0       0       0       0       0       0   \n",
       "27997       0       0       0       0       0       0       0       0       0   \n",
       "27998       0       0       0       0       0       0       0       0       0   \n",
       "27999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "27995       0  ...         0         0         0         0         0   \n",
       "27996       0  ...         0         0         0         0         0   \n",
       "27997       0  ...         0         0         0         0         0   \n",
       "27998       0  ...         0         0         0         0         0   \n",
       "27999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27995         0         0         0         0         0  \n",
       "27996         0         0         0         0         0  \n",
       "27997         0         0         0         0         0  \n",
       "27998         0         0         0         0         0  \n",
       "27999         0         0         0         0         0  \n",
       "\n",
       "[28000 rows x 784 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label'],1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 7, 6, 9])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label'],1).values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35700, 784)\n",
      "(35700,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35700, 28, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X_train.reshape(35700,28,28)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 784)\n",
      "(6300,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35700, 28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=X_test.reshape(6300,28,28)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor=torch.from_numpy(X_train)\n",
    "X_test_tensor=torch.from_numpy(X_test)\n",
    "print(type(X_train_tensor))\n",
    "print(type(X_test_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35700, 1, 28, 28])\n",
      "torch.Size([6300, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# add a dimension to tensor to become B*C*H*W \n",
    "if len(X_train.shape)==3:\n",
    "    X_train_tensor = X_train_tensor.unsqueeze(1) \n",
    "print(X_train_tensor.shape)\n",
    "if len(X_test.shape)==3: \n",
    "    X_test_tensor = X_test_tensor.unsqueeze(1)\n",
    "print(X_test_tensor.shape)\n",
    "\n",
    "#torch.Size([35700, 1, 28, 28]) \n",
    "#torch.Size([6300, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "## transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor=torch.from_numpy(y_train)\n",
    "y_test_tensor=torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "# wrap tensors into a dataset\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor) \n",
    "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "for x,y in train_ds: \n",
    "    print(x.shape,y.item()) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 28, 28])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# create a data loader from dataset\n",
    "train_dl = DataLoader(train_ds, batch_size=8) \n",
    "test_dl = DataLoader(test_ds, batch_size=8)\n",
    "            # iterate over batches\n",
    "for xb,yb in train_dl:\n",
    "    print(xb.shape) \n",
    "    print(yb.shape) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=5, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "# define a two-layer model \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 5), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(5, 1),\n",
    "            )\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-07fee37f2bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m             raise RuntimeError(\n\u001b[1;32m    185\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") \n",
    "model.to(device)\n",
    "print(next(model.parameters()).device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
