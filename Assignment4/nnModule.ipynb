{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnModule.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxzeu7k48ravYl77Ac8IKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaraRasti/Deep_Learning_F20_Assignments/blob/master/Assignment4/nnModule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5wb3GhBbjU9"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "pathdata='/content/drive/My Drive/dataFMNIST'\n",
        "\n",
        "transformations = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([.5],[.5])\n",
        "                                      ])\n",
        "\n",
        "\n",
        "data=datasets.FashionMNIST(pathdata,train=True, download=True,transform=transformations)\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(data, [42000, 18000])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,shuffle=True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXi-TNw1bkoI"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=300, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.fc3 = nn.Linear(in_features=60, out_features=30)\n",
        "        self.out = nn.Linear(in_features=30, out_features=10)\n",
        "\n",
        "    def forward(self, t):\n",
        "\n",
        "        t = F.relu(self.conv1(t))\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "        t = torch.sigmoid(self.conv2(t))\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "        t = t.flatten(start_dim=1)\n",
        "        t = F.relu(self.fc1(t))\n",
        "        t = F.relu(self.fc2(t))\n",
        "        t = F.softmax(self.fc3(t))\n",
        "        t = self.out(t)\n",
        "\n",
        "        return t\n",
        "\n",
        "    def training_step(self, batch):\n",
        "      images, labels = batch\n",
        "      out = self(images)\n",
        "      loss = loss_fn(out, labels)\n",
        "      return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "      images, labels = batch\n",
        "      out = self(images)\n",
        "      loss = loss_fn(out, labels)\n",
        "      acc = accuracy(out, labels)\n",
        "      return {'test_loss': loss.detach(), 'test_acc':acc.detach()}\n",
        "  \n",
        "    def validation_epoch_end(self, outputs):\n",
        "      batch_losses = [x['test_loss'] for x in outputs]\n",
        "      epoch_loss = torch.stack(batch_losses).mean()\n",
        "      batch_accs = [x['test_acc'] for x in outputs]\n",
        "      epoch_acc = torch.stack(batch_accs).mean()\n",
        "      return {'test_loss':epoch_loss.item(), 'test_acc':epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "      print(\"Epoch [{}], test_loss: {:.4f}, test_acc: {:.4f}\".format(epoch, result['test_loss'], result['test_acc']))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXO-pp4PcXIs"
      },
      "source": [
        "model=Network()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWuZO0nrcrgW"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item()/len(preds))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ0arlhJcw1P"
      },
      "source": [
        "def evaluate(model, test_loader):\n",
        "  outputs = [model.validation_step(batch) for batch in test_loader]\n",
        "  return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, test_loader, opt_func=torch.optim.SGD):\n",
        "  history = []\n",
        "  optimizer = opt_func(model.parameters(), lr)\n",
        "  for epoch in range(epochs):\n",
        "    for batch in train_loader:\n",
        "      loss = model.training_step(batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "    result = evaluate(model, test_loader)\n",
        "    model.epoch_end(epoch, result)\n",
        "    history.append(result)\n",
        "  return history"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4dzZ63kezgg"
      },
      "source": [
        "loss_fn = F.cross_entropy\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-cbH3LddAX-",
        "outputId": "70e5273d-530c-470d-ed77-bae7bfb422f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_acc': 0.0985555574297905, 'test_loss': 2.3028807640075684}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J94-EoSpdF7F",
        "outputId": "48ca41b7-b50b-4fde-eb6e-3381f20cd3f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "history = fit(20, learning_rate, model, train_loader, test_loader)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], test_loss: 2.3028, test_acc: 0.1003\n",
            "Epoch [1], test_loss: 2.3027, test_acc: 0.0992\n",
            "Epoch [2], test_loss: 2.3027, test_acc: 0.0966\n",
            "Epoch [3], test_loss: 2.3024, test_acc: 0.1013\n",
            "Epoch [4], test_loss: 2.3025, test_acc: 0.0986\n",
            "Epoch [5], test_loss: 2.3025, test_acc: 0.1015\n",
            "Epoch [6], test_loss: 2.3023, test_acc: 0.1717\n",
            "Epoch [7], test_loss: 2.3021, test_acc: 0.0966\n",
            "Epoch [8], test_loss: 2.3011, test_acc: 0.1004\n",
            "Epoch [9], test_loss: 2.2978, test_acc: 0.1221\n",
            "Epoch [10], test_loss: 2.1431, test_acc: 0.2065\n",
            "Epoch [11], test_loss: 1.6384, test_acc: 0.3308\n",
            "Epoch [12], test_loss: 1.4859, test_acc: 0.3508\n",
            "Epoch [13], test_loss: 1.4316, test_acc: 0.3518\n",
            "Epoch [14], test_loss: 1.3979, test_acc: 0.3437\n",
            "Epoch [15], test_loss: 1.3542, test_acc: 0.4661\n",
            "Epoch [16], test_loss: 1.3053, test_acc: 0.5098\n",
            "Epoch [17], test_loss: 1.2553, test_acc: 0.5546\n",
            "Epoch [18], test_loss: 1.2342, test_acc: 0.5138\n",
            "Epoch [19], test_loss: 1.1846, test_acc: 0.5837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NZtQ1VtbTW",
        "outputId": "305ef903-c753-44c7-b490-6039abaed18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "history = fit(50, learning_rate, model, train_loader, test_loader)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], test_loss: 1.0300, test_acc: 0.6747\n",
            "Epoch [1], test_loss: 1.0134, test_acc: 0.6883\n",
            "Epoch [2], test_loss: 0.9919, test_acc: 0.6734\n",
            "Epoch [3], test_loss: 0.9722, test_acc: 0.6786\n",
            "Epoch [4], test_loss: 0.9582, test_acc: 0.6836\n",
            "Epoch [5], test_loss: 0.9340, test_acc: 0.6994\n",
            "Epoch [6], test_loss: 0.9149, test_acc: 0.6912\n",
            "Epoch [7], test_loss: 0.9092, test_acc: 0.6896\n",
            "Epoch [8], test_loss: 0.8844, test_acc: 0.7086\n",
            "Epoch [9], test_loss: 0.8748, test_acc: 0.7037\n",
            "Epoch [10], test_loss: 0.8632, test_acc: 0.7315\n",
            "Epoch [11], test_loss: 0.8371, test_acc: 0.7472\n",
            "Epoch [12], test_loss: 0.8276, test_acc: 0.7418\n",
            "Epoch [13], test_loss: 0.8372, test_acc: 0.7248\n",
            "Epoch [14], test_loss: 0.7932, test_acc: 0.7584\n",
            "Epoch [15], test_loss: 0.7886, test_acc: 0.7583\n",
            "Epoch [16], test_loss: 0.7675, test_acc: 0.7604\n",
            "Epoch [17], test_loss: 0.7623, test_acc: 0.7612\n",
            "Epoch [18], test_loss: 0.7457, test_acc: 0.7600\n",
            "Epoch [19], test_loss: 0.7392, test_acc: 0.7648\n",
            "Epoch [20], test_loss: 0.7423, test_acc: 0.7575\n",
            "Epoch [21], test_loss: 0.7297, test_acc: 0.7605\n",
            "Epoch [22], test_loss: 0.7158, test_acc: 0.7595\n",
            "Epoch [23], test_loss: 0.7162, test_acc: 0.7617\n",
            "Epoch [24], test_loss: 0.7057, test_acc: 0.7621\n",
            "Epoch [25], test_loss: 0.6934, test_acc: 0.7696\n",
            "Epoch [26], test_loss: 0.6924, test_acc: 0.7616\n",
            "Epoch [27], test_loss: 0.6756, test_acc: 0.7647\n",
            "Epoch [28], test_loss: 0.6713, test_acc: 0.7665\n",
            "Epoch [29], test_loss: 0.6686, test_acc: 0.7668\n",
            "Epoch [30], test_loss: 0.6658, test_acc: 0.7663\n",
            "Epoch [31], test_loss: 0.6526, test_acc: 0.7684\n",
            "Epoch [32], test_loss: 0.6497, test_acc: 0.7717\n",
            "Epoch [33], test_loss: 0.6542, test_acc: 0.7691\n",
            "Epoch [34], test_loss: 0.6517, test_acc: 0.7666\n",
            "Epoch [35], test_loss: 0.6396, test_acc: 0.7798\n",
            "Epoch [36], test_loss: 0.6176, test_acc: 0.7952\n",
            "Epoch [37], test_loss: 0.6099, test_acc: 0.7951\n",
            "Epoch [38], test_loss: 0.6146, test_acc: 0.7984\n",
            "Epoch [39], test_loss: 0.6109, test_acc: 0.8049\n",
            "Epoch [40], test_loss: 0.6003, test_acc: 0.8043\n",
            "Epoch [41], test_loss: 0.5931, test_acc: 0.8078\n",
            "Epoch [42], test_loss: 0.5826, test_acc: 0.8052\n",
            "Epoch [43], test_loss: 0.5821, test_acc: 0.8074\n",
            "Epoch [44], test_loss: 0.5721, test_acc: 0.8139\n",
            "Epoch [45], test_loss: 0.5881, test_acc: 0.8144\n",
            "Epoch [46], test_loss: 0.5653, test_acc: 0.8131\n",
            "Epoch [47], test_loss: 0.5778, test_acc: 0.8142\n",
            "Epoch [48], test_loss: 0.5635, test_acc: 0.8098\n",
            "Epoch [49], test_loss: 0.5583, test_acc: 0.8159\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}