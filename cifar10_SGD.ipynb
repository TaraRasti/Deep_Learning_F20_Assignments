{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-SGD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSezicTH0qMrlKX2d+l35d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaraRasti/Deep_Learning_F20_Assignments/blob/master/cifar10_SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HooCuGDj0S_v",
        "outputId": "e99a5a91-fc47-4375-d7a2-b8ad22767184"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "#z-score\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "\n",
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)\n",
        "\n",
        "baseMapNum = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l1(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "#training\n",
        "batch_size = 64\n",
        "epochs=25\n",
        "opt_rms = keras.optimizers.SGD(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep75.h5')\n",
        "\n",
        "opt_rms = keras.optimizers.SGD(lr=0.0005,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep100.h5')\n",
        "\n",
        "opt_rms = keras.optimizers.SGD(lr=0.0003,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep125.h5')\n",
        "\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Epoch 1/75\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 3.7005 - accuracy: 0.2519 - val_loss: 2.5059 - val_accuracy: 0.4166\n",
            "Epoch 2/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 3.0041 - accuracy: 0.3377 - val_loss: 2.3460 - val_accuracy: 0.4592\n",
            "Epoch 3/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.7671 - accuracy: 0.3765 - val_loss: 2.2572 - val_accuracy: 0.4884\n",
            "Epoch 4/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.6210 - accuracy: 0.4083 - val_loss: 2.2086 - val_accuracy: 0.5074\n",
            "Epoch 5/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.5452 - accuracy: 0.4265 - val_loss: 2.1963 - val_accuracy: 0.5173\n",
            "Epoch 6/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.4729 - accuracy: 0.4456 - val_loss: 2.1913 - val_accuracy: 0.5178\n",
            "Epoch 7/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.4126 - accuracy: 0.4625 - val_loss: 2.1490 - val_accuracy: 0.5342\n",
            "Epoch 8/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.3721 - accuracy: 0.4757 - val_loss: 2.1432 - val_accuracy: 0.5335\n",
            "Epoch 9/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.3298 - accuracy: 0.4841 - val_loss: 2.1821 - val_accuracy: 0.5290\n",
            "Epoch 10/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.2880 - accuracy: 0.4966 - val_loss: 2.1587 - val_accuracy: 0.5355\n",
            "Epoch 11/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.2588 - accuracy: 0.5078 - val_loss: 2.1158 - val_accuracy: 0.5463\n",
            "Epoch 12/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.2223 - accuracy: 0.5141 - val_loss: 2.1690 - val_accuracy: 0.5299\n",
            "Epoch 13/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.1888 - accuracy: 0.5244 - val_loss: 2.0551 - val_accuracy: 0.5635\n",
            "Epoch 14/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.1562 - accuracy: 0.5347 - val_loss: 2.0637 - val_accuracy: 0.5622\n",
            "Epoch 15/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.1333 - accuracy: 0.5408 - val_loss: 2.1105 - val_accuracy: 0.5488\n",
            "Epoch 16/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.0997 - accuracy: 0.5519 - val_loss: 2.0731 - val_accuracy: 0.5601\n",
            "Epoch 17/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.0727 - accuracy: 0.5618 - val_loss: 2.0514 - val_accuracy: 0.5690\n",
            "Epoch 18/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.0531 - accuracy: 0.5643 - val_loss: 2.0324 - val_accuracy: 0.5697\n",
            "Epoch 19/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.0373 - accuracy: 0.5707 - val_loss: 1.9993 - val_accuracy: 0.5774\n",
            "Epoch 20/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 2.0143 - accuracy: 0.5785 - val_loss: 2.0028 - val_accuracy: 0.5784\n",
            "Epoch 21/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.9908 - accuracy: 0.5829 - val_loss: 1.9757 - val_accuracy: 0.5886\n",
            "Epoch 22/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.9731 - accuracy: 0.5920 - val_loss: 1.9892 - val_accuracy: 0.5818\n",
            "Epoch 23/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.9565 - accuracy: 0.5935 - val_loss: 1.9684 - val_accuracy: 0.5864\n",
            "Epoch 24/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.9440 - accuracy: 0.5968 - val_loss: 1.9499 - val_accuracy: 0.5985\n",
            "Epoch 25/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.9274 - accuracy: 0.6033 - val_loss: 1.9282 - val_accuracy: 0.6000\n",
            "Epoch 26/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.9134 - accuracy: 0.6077 - val_loss: 1.9268 - val_accuracy: 0.6037\n",
            "Epoch 27/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.8942 - accuracy: 0.6138 - val_loss: 1.9095 - val_accuracy: 0.6023\n",
            "Epoch 28/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.8853 - accuracy: 0.6167 - val_loss: 1.9174 - val_accuracy: 0.6051\n",
            "Epoch 29/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.8726 - accuracy: 0.6196 - val_loss: 1.9325 - val_accuracy: 0.6005\n",
            "Epoch 30/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.8611 - accuracy: 0.6242 - val_loss: 1.9006 - val_accuracy: 0.6099\n",
            "Epoch 31/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.8488 - accuracy: 0.6257 - val_loss: 1.8764 - val_accuracy: 0.6156\n",
            "Epoch 32/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.8296 - accuracy: 0.6303 - val_loss: 1.8777 - val_accuracy: 0.6154\n",
            "Epoch 33/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.8232 - accuracy: 0.6353 - val_loss: 1.8848 - val_accuracy: 0.6148\n",
            "Epoch 34/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.8107 - accuracy: 0.6385 - val_loss: 1.8921 - val_accuracy: 0.6145\n",
            "Epoch 35/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.8038 - accuracy: 0.6398 - val_loss: 1.8862 - val_accuracy: 0.6129\n",
            "Epoch 36/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.7903 - accuracy: 0.6425 - val_loss: 1.8162 - val_accuracy: 0.6329\n",
            "Epoch 37/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.7795 - accuracy: 0.6444 - val_loss: 1.8129 - val_accuracy: 0.6359\n",
            "Epoch 38/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.7677 - accuracy: 0.6512 - val_loss: 1.8058 - val_accuracy: 0.6385\n",
            "Epoch 39/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.7600 - accuracy: 0.6519 - val_loss: 1.7853 - val_accuracy: 0.6455\n",
            "Epoch 40/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.7588 - accuracy: 0.6518 - val_loss: 1.7534 - val_accuracy: 0.6527\n",
            "Epoch 41/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.7404 - accuracy: 0.6554 - val_loss: 1.7879 - val_accuracy: 0.6428\n",
            "Epoch 42/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.7388 - accuracy: 0.6572 - val_loss: 1.7497 - val_accuracy: 0.6554\n",
            "Epoch 43/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.7278 - accuracy: 0.6586 - val_loss: 1.7190 - val_accuracy: 0.6624\n",
            "Epoch 44/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 1.7156 - accuracy: 0.6634 - val_loss: 1.7035 - val_accuracy: 0.6686\n",
            "Epoch 45/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.7099 - accuracy: 0.6637 - val_loss: 1.7563 - val_accuracy: 0.6531\n",
            "Epoch 46/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.6964 - accuracy: 0.6692 - val_loss: 1.7358 - val_accuracy: 0.6603\n",
            "Epoch 47/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.6979 - accuracy: 0.6668 - val_loss: 1.7043 - val_accuracy: 0.6675\n",
            "Epoch 48/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.6857 - accuracy: 0.6708 - val_loss: 1.7281 - val_accuracy: 0.6585\n",
            "Epoch 49/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.6872 - accuracy: 0.6722 - val_loss: 1.7254 - val_accuracy: 0.6634\n",
            "Epoch 50/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.6725 - accuracy: 0.6739 - val_loss: 1.7159 - val_accuracy: 0.6623\n",
            "Epoch 51/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.6633 - accuracy: 0.6800 - val_loss: 1.6951 - val_accuracy: 0.6717\n",
            "Epoch 52/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.6560 - accuracy: 0.6809 - val_loss: 1.6890 - val_accuracy: 0.6694\n",
            "Epoch 53/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.6502 - accuracy: 0.6821 - val_loss: 1.6643 - val_accuracy: 0.6800\n",
            "Epoch 54/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.6393 - accuracy: 0.6851 - val_loss: 1.6531 - val_accuracy: 0.6877\n",
            "Epoch 55/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.6381 - accuracy: 0.6817 - val_loss: 1.6440 - val_accuracy: 0.6856\n",
            "Epoch 56/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.6332 - accuracy: 0.6848 - val_loss: 1.6991 - val_accuracy: 0.6704\n",
            "Epoch 57/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.6257 - accuracy: 0.6860 - val_loss: 1.6587 - val_accuracy: 0.6863\n",
            "Epoch 58/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.6137 - accuracy: 0.6896 - val_loss: 1.6525 - val_accuracy: 0.6841\n",
            "Epoch 59/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.6078 - accuracy: 0.6906 - val_loss: 1.6404 - val_accuracy: 0.6829\n",
            "Epoch 60/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5983 - accuracy: 0.6926 - val_loss: 1.6230 - val_accuracy: 0.6935\n",
            "Epoch 61/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.5963 - accuracy: 0.6955 - val_loss: 1.6200 - val_accuracy: 0.6924\n",
            "Epoch 62/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5875 - accuracy: 0.6967 - val_loss: 1.6180 - val_accuracy: 0.6915\n",
            "Epoch 63/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5790 - accuracy: 0.6989 - val_loss: 1.6407 - val_accuracy: 0.6851\n",
            "Epoch 64/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5789 - accuracy: 0.7003 - val_loss: 1.6142 - val_accuracy: 0.6907\n",
            "Epoch 65/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5705 - accuracy: 0.6997 - val_loss: 1.6029 - val_accuracy: 0.6959\n",
            "Epoch 66/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5628 - accuracy: 0.7023 - val_loss: 1.5913 - val_accuracy: 0.7020\n",
            "Epoch 67/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5591 - accuracy: 0.7034 - val_loss: 1.5543 - val_accuracy: 0.7065\n",
            "Epoch 68/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5508 - accuracy: 0.7077 - val_loss: 1.5814 - val_accuracy: 0.7024\n",
            "Epoch 69/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5529 - accuracy: 0.7055 - val_loss: 1.5644 - val_accuracy: 0.7081\n",
            "Epoch 70/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5431 - accuracy: 0.7072 - val_loss: 1.5438 - val_accuracy: 0.7119\n",
            "Epoch 71/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.5432 - accuracy: 0.7066 - val_loss: 1.5485 - val_accuracy: 0.7111\n",
            "Epoch 72/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5333 - accuracy: 0.7069 - val_loss: 1.5661 - val_accuracy: 0.7040\n",
            "Epoch 73/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5262 - accuracy: 0.7114 - val_loss: 1.5316 - val_accuracy: 0.7142\n",
            "Epoch 74/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.5208 - accuracy: 0.7111 - val_loss: 1.5389 - val_accuracy: 0.7134\n",
            "Epoch 75/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5139 - accuracy: 0.7124 - val_loss: 1.5420 - val_accuracy: 0.7120\n",
            "Epoch 1/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5053 - accuracy: 0.7147 - val_loss: 1.5336 - val_accuracy: 0.7124\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4970 - accuracy: 0.7187 - val_loss: 1.5317 - val_accuracy: 0.7150\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5006 - accuracy: 0.7181 - val_loss: 1.5153 - val_accuracy: 0.7186\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4912 - accuracy: 0.7212 - val_loss: 1.5071 - val_accuracy: 0.7205\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4900 - accuracy: 0.7197 - val_loss: 1.5185 - val_accuracy: 0.7192\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4865 - accuracy: 0.7215 - val_loss: 1.5172 - val_accuracy: 0.7186\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4912 - accuracy: 0.7213 - val_loss: 1.5113 - val_accuracy: 0.7211\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4853 - accuracy: 0.7205 - val_loss: 1.5126 - val_accuracy: 0.7201\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4789 - accuracy: 0.7230 - val_loss: 1.4954 - val_accuracy: 0.7264\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4811 - accuracy: 0.7217 - val_loss: 1.5104 - val_accuracy: 0.7205\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4828 - accuracy: 0.7200 - val_loss: 1.5069 - val_accuracy: 0.7192\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4710 - accuracy: 0.7267 - val_loss: 1.4933 - val_accuracy: 0.7229\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4712 - accuracy: 0.7233 - val_loss: 1.4997 - val_accuracy: 0.7202\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4673 - accuracy: 0.7254 - val_loss: 1.5063 - val_accuracy: 0.7194\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4638 - accuracy: 0.7263 - val_loss: 1.4760 - val_accuracy: 0.7285\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4624 - accuracy: 0.7266 - val_loss: 1.4699 - val_accuracy: 0.7303\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4594 - accuracy: 0.7263 - val_loss: 1.4791 - val_accuracy: 0.7252\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4585 - accuracy: 0.7245 - val_loss: 1.4730 - val_accuracy: 0.7282\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4575 - accuracy: 0.7290 - val_loss: 1.4806 - val_accuracy: 0.7252\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4519 - accuracy: 0.7287 - val_loss: 1.4665 - val_accuracy: 0.7283\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4494 - accuracy: 0.7301 - val_loss: 1.4624 - val_accuracy: 0.7319\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4494 - accuracy: 0.7289 - val_loss: 1.4550 - val_accuracy: 0.7347\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4426 - accuracy: 0.7314 - val_loss: 1.4728 - val_accuracy: 0.7290\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4381 - accuracy: 0.7317 - val_loss: 1.4644 - val_accuracy: 0.7294\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4405 - accuracy: 0.7312 - val_loss: 1.4622 - val_accuracy: 0.7288\n",
            "Epoch 1/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4319 - accuracy: 0.7348 - val_loss: 1.4472 - val_accuracy: 0.7358\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4295 - accuracy: 0.7362 - val_loss: 1.4580 - val_accuracy: 0.7309\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4356 - accuracy: 0.7341 - val_loss: 1.4575 - val_accuracy: 0.7327\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4305 - accuracy: 0.7334 - val_loss: 1.4531 - val_accuracy: 0.7306\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4288 - accuracy: 0.7344 - val_loss: 1.4430 - val_accuracy: 0.7337\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4282 - accuracy: 0.7366 - val_loss: 1.4527 - val_accuracy: 0.7335\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4319 - accuracy: 0.7330 - val_loss: 1.4375 - val_accuracy: 0.7376\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4228 - accuracy: 0.7346 - val_loss: 1.4552 - val_accuracy: 0.7302\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4219 - accuracy: 0.7366 - val_loss: 1.4412 - val_accuracy: 0.7357\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4214 - accuracy: 0.7362 - val_loss: 1.4348 - val_accuracy: 0.7378\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4214 - accuracy: 0.7340 - val_loss: 1.4473 - val_accuracy: 0.7350\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4197 - accuracy: 0.7349 - val_loss: 1.4495 - val_accuracy: 0.7336\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4166 - accuracy: 0.7377 - val_loss: 1.4328 - val_accuracy: 0.7392\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4168 - accuracy: 0.7379 - val_loss: 1.4460 - val_accuracy: 0.7347\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4152 - accuracy: 0.7362 - val_loss: 1.4400 - val_accuracy: 0.7361\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4117 - accuracy: 0.7368 - val_loss: 1.4283 - val_accuracy: 0.7399\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4113 - accuracy: 0.7379 - val_loss: 1.4204 - val_accuracy: 0.7422\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4115 - accuracy: 0.7376 - val_loss: 1.4246 - val_accuracy: 0.7428\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4106 - accuracy: 0.7386 - val_loss: 1.4297 - val_accuracy: 0.7384\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4055 - accuracy: 0.7381 - val_loss: 1.4324 - val_accuracy: 0.7370\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4066 - accuracy: 0.7373 - val_loss: 1.4490 - val_accuracy: 0.7343\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4025 - accuracy: 0.7407 - val_loss: 1.4375 - val_accuracy: 0.7377\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4007 - accuracy: 0.7426 - val_loss: 1.4154 - val_accuracy: 0.7426\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.3965 - accuracy: 0.7435 - val_loss: 1.4279 - val_accuracy: 0.7387\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4039 - accuracy: 0.7400 - val_loss: 1.4210 - val_accuracy: 0.7412\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4210 - accuracy: 0.7412\n",
            "\n",
            "Test result: 74.120 loss: 1.421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAmQeCnCd0h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}